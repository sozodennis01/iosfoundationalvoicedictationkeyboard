{"identifier":{"url":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer","interfaceLanguage":"swift"},"schemaVersion":{"major":0,"minor":3,"patch":0},"primaryContentSections":[{"kind":"declarations","declarations":[{"languages":["swift"],"tokens":[{"kind":"keyword","text":"final"},{"text":" ","kind":"text"},{"text":"actor","kind":"keyword"},{"kind":"text","text":" "},{"text":"SpeechAnalyzer","kind":"identifier"}],"platforms":["iOS","iPadOS","Mac Catalyst","macOS","visionOS"]}]},{"kind":"content","content":[{"type":"heading","anchor":"overview","text":"Overview","level":2},{"type":"paragraph","inlineContent":[{"text":"The Speech framework provides several modules that can be added to an analyzer to provide specific types of analysis and transcription. Many use cases only need a ","type":"text"},{"identifier":"doc://com.apple.speech/documentation/Speech/SpeechTranscriber","type":"reference","isActive":true},{"type":"text","text":" module, which performs speech-to-text transcriptions."}]},{"type":"paragraph","inlineContent":[{"text":"The ","type":"text"},{"code":"SpeechAnalyzer","type":"codeVoice"},{"type":"text","text":" class is responsible for:"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Holding associated modules","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Accepting audio speech input","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Controlling the overall analysis","type":"text"}]}]}]},{"inlineContent":[{"text":"Each module is responsible for:","type":"text"}],"type":"paragraph"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"Providing guidance on acceptable input","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Providing its analysis or transcription output","type":"text"}]}]}]},{"inlineContent":[{"text":"Analysis is asynchronous. Input, output, and session control are decoupled and typically occur over several different tasks created by you or by the session. In particular, where an Objective-C API might use a delegate to provide results to you, the Swift API’s modules provides their results via an ","type":"text"},{"type":"codeVoice","code":"AsyncSequence"},{"type":"text","text":". Similarly, you provide speech input to this API via an "},{"type":"codeVoice","code":"AsyncSequence"},{"type":"text","text":" you create and populate."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"The analyzer can only analyze one input sequence at a time."}],"type":"paragraph"},{"anchor":"Perform-analysis","type":"heading","level":3,"text":"Perform analysis"},{"inlineContent":[{"type":"text","text":"To perform analysis on audio files and streams, follow these general steps:"}],"type":"paragraph"},{"type":"orderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Create and configure the necessary modules."}]}]},{"content":[{"inlineContent":[{"text":"Ensure the relevant assets are installed or already present. See ","type":"text"},{"isActive":true,"identifier":"doc://com.apple.speech/documentation/Speech/AssetInventory","type":"reference"},{"type":"text","text":"."}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Create an input sequence you can use to provide the spoken audio.","type":"text"}]}]},{"content":[{"inlineContent":[{"type":"text","text":"Create and configure the analyzer with the modules and input sequence."}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"text":"Supply audio.","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Start analysis.","type":"text"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Act on results."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"text":"Finish analysis when desired.","type":"text"}]}]}]},{"inlineContent":[{"type":"text","text":"This example shows how you could perform an analysis that transcribes audio using the "},{"code":"SpeechTranscriber","type":"codeVoice"},{"type":"text","text":" module:"}],"type":"paragraph"},{"syntax":"swift","code":["import Speech","","// Step 1: Modules","guard let locale = SpeechTranscriber.supportedLocale(equivalentTo: Locale.current) else {","    /* Note unsupported language */","}","let transcriber = SpeechTranscriber(locale: locale, preset: .offlineTranscription)","","// Step 2: Assets","if let installationRequest = try await AssetInventory.assetInstallationRequest(supporting: [transcriber]) {","    try await installationRequest.downloadAndInstall()","}","","// Step 3: Input sequence","let (inputSequence, inputBuilder) = AsyncStream.makeStream(of: AnalyzerInput.self)","","// Step 4: Analyzer","let audioFormat = await SpeechAnalyzer.bestAvailableAudioFormat(compatibleWith: [transcriber])","let analyzer = SpeechAnalyzer(modules: [transcriber])","","// Step 5: Supply audio","Task {","    while /* audio remains */ {","        /* Get some audio */","        /* Convert to audioFormat */","        let pcmBuffer = /* an AVAudioPCMBuffer containing some converted audio */","        let input = AnalyzerInput(buffer: pcmBuffer)","        inputBuilder.yield(input)","    }","    inputBuilder.finish()","}","","// Step 7: Act on results","Task {","    do {","        for try await result in transcriber.results {","            let bestTranscription = result.text // an AttributedString","            let plainTextBestTranscription = String(bestTranscription.characters) // a String","            print(plainTextBestTranscription)","        }","    } catch {","        /* Handle error */","    }","}","","// Step 6: Perform analysis","let lastSampleTime = try await analyzer.analyzeSequence(inputSequence)","","// Step 8: Finish analysis","if let lastSampleTime {","    try await analyzer.finalizeAndFinish(through: lastSampleTime)","} else {","    try analyzer.cancelAndFinishNow()","}"],"type":"codeListing"},{"type":"heading","level":3,"anchor":"Analyze-audio-files","text":"Analyze audio files"},{"inlineContent":[{"text":"To analyze one or more audio files represented by an ","type":"text"},{"code":"AVAudioFile","type":"codeVoice"},{"type":"text","text":" object, call methods such as "},{"type":"reference","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/analyzeSequence(from:)","isActive":true},{"type":"text","text":" or "},{"isActive":true,"type":"reference","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/start(inputAudioFile:finishAfterFile:)"},{"text":", or create the analyzer with one of the initializers that has a file parameter. These methods automatically convert the file to a supported audio format and process the file in its entirety.","type":"text"}],"type":"paragraph"},{"type":"paragraph","inlineContent":[{"type":"text","text":"To end the analysis session after one file, pass "},{"code":"true","type":"codeVoice"},{"text":" for the ","type":"text"},{"type":"codeVoice","code":"finishAfterFile"},{"text":" parameter or call one of the ","type":"text"},{"type":"codeVoice","code":"finish"},{"type":"text","text":" methods."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Otherwise, by default, the analyzer won’t terminate its result streams and will wait for additional audio files or buffers. The analysis session doesn’t reset the audio timeline after each file; the next audio is assumed to come immediately after the completed file."}]},{"text":"Analyze audio buffers","anchor":"Analyze-audio-buffers","level":3,"type":"heading"},{"inlineContent":[{"type":"text","text":"To analyze audio buffers directly, convert them to a supported audio format, either on the fly or in advance. You can use "},{"isActive":true,"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/bestAvailableAudioFormat(compatibleWith:)","type":"reference"},{"text":" or individual modules’ ","type":"text"},{"isActive":true,"type":"reference","identifier":"doc://com.apple.speech/documentation/Speech/SpeechModule/availableCompatibleAudioFormats"},{"text":" methods to select a format to convert to.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"Create an ","type":"text"},{"identifier":"doc://com.apple.speech/documentation/Speech/AnalyzerInput","isActive":true,"type":"reference"},{"type":"text","text":" object for each audio buffer and add the object to an input sequence you create. Supply that input sequence to "},{"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/analyzeSequence(_:)","type":"reference","isActive":true},{"type":"text","text":", "},{"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/start(inputSequence:)","isActive":true,"type":"reference"},{"text":", or a similar parameter of the analyzer’s initializer.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"To skip past part of an audio stream, omit the buffers you want to skip from the input sequence. When you resume analysis with a later buffer, you can ensure the time-code of each module’s result accounts for the skipped audio. To do this, pass the later buffer’s time-code within the audio stream as the "},{"type":"codeVoice","code":"bufferStartTime"},{"text":" parameter of the later ","type":"text"},{"type":"codeVoice","code":"AnalyzerInput"},{"text":" object.","type":"text"}],"type":"paragraph"},{"text":"Analyze autonomously","anchor":"Analyze-autonomously","type":"heading","level":3},{"inlineContent":[{"text":"You can and usually should perform analysis using the ","type":"text"},{"isActive":true,"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/analyzeSequence(_:)","type":"reference"},{"text":" or ","type":"text"},{"type":"reference","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/analyzeSequence(from:)","isActive":true},{"type":"text","text":" methods; those methods work well with Swift structured concurrency techniques. However, you may prefer that the analyzer proceed independently and perform its analysis autonomously as audio input becomes available in a task managed by the analyzer itself."}],"type":"paragraph"},{"type":"paragraph","inlineContent":[{"text":"To use this capability, create the analyzer with one of the initializers that has an input sequence or file parameter, or call ","type":"text"},{"isActive":true,"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/start(inputSequence:)","type":"reference"},{"type":"text","text":" or "},{"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/start(inputAudioFile:finishAfterFile:)","isActive":true,"type":"reference"},{"type":"text","text":". To end the analysis when the input ends, call "},{"type":"reference","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finalizeAndFinishThroughEndOfInput()","isActive":true},{"type":"text","text":". To end the analysis of that input and start analysis of different input, call one of the "},{"code":"start","type":"codeVoice"},{"text":" methods again.","type":"text"}]},{"type":"heading","anchor":"Control-processing-and-timing-of-results","level":3,"text":"Control processing and timing of results"},{"type":"paragraph","inlineContent":[{"type":"text","text":"Modules deliver results periodically, but you can manually synchronize their processing and delivery to outside cues."}]},{"inlineContent":[{"type":"text","text":"To deliver a result for a particular time-code, call "},{"type":"reference","isActive":true,"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finalize(through:)"},{"type":"text","text":". To cancel processing of results that are no longer of interest, call "},{"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/cancelAnalysis(before:)","isActive":true,"type":"reference"},{"text":".","type":"text"}],"type":"paragraph"},{"text":"Improve responsiveness","level":3,"type":"heading","anchor":"Improve-responsiveness"},{"inlineContent":[{"type":"text","text":"By default, the analyzer and modules load the system resources that they require lazily, and unload those resources when they’re deallocated."}],"type":"paragraph"},{"inlineContent":[{"text":"To proactively load system resources and “preheat” the analyzer, call ","type":"text"},{"isActive":true,"type":"reference","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/prepareToAnalyze(in:)"},{"text":" after setting its modules. This may improve how quickly the modules return their first results.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"To delay or prevent unloading an analyzer’s resources — caching them for later use by a different analyzer instance — you can select a ","type":"text"},{"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/Options/ModelRetention-swift.enum","isActive":true,"type":"reference"},{"type":"text","text":" option and create the analyzer with an appropriate "},{"isActive":true,"type":"reference","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/Options"},{"type":"text","text":" object."}],"type":"paragraph"},{"inlineContent":[{"type":"text","text":"To set the priority of analysis work, create the analyzer with a "},{"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/Options","isActive":true,"type":"reference"},{"type":"text","text":" object given a "},{"type":"codeVoice","code":"priority"},{"type":"text","text":" value."}],"type":"paragraph"},{"type":"paragraph","inlineContent":[{"text":"Specific modules may also offer options that improve responsiveness.","type":"text"}]},{"text":"Finish analysis","anchor":"Finish-analysis","type":"heading","level":3},{"inlineContent":[{"type":"text","text":"To end an analysis session, you must use one of the analyzer’s "},{"type":"codeVoice","code":"finish"},{"text":" methods or parameters, or deallocate the analyzer.","type":"text"}],"type":"paragraph"},{"inlineContent":[{"text":"When the analysis session transitions to the ","type":"text"},{"type":"emphasis","inlineContent":[{"text":"finished","type":"text"}]},{"text":" state:","type":"text"}],"type":"paragraph"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"text":"The analyzer won’t take additional input from the input sequence","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Most methods won’t do anything; in particular, the analyzer won’t accept different input sequences or modules"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"text","text":"Module result streams terminate and modules won’t publish additional results, though the app can continue to iterate over already-published results"}],"type":"paragraph"}]}]},{"style":"note","name":"Note","type":"aside","content":[{"inlineContent":[{"type":"text","text":"While you can terminate the input sequence you created with a method such as "},{"type":"codeVoice","code":"AsyncStream.Continuation.finish()"},{"type":"text","text":", finishing the input sequence does "},{"type":"emphasis","inlineContent":[{"type":"text","text":"not"}]},{"text":" cause the analysis session to become finished, and you can continue the session with a different input sequence.","type":"text"}],"type":"paragraph"}]},{"text":"Respond to errors","type":"heading","level":3,"anchor":"Respond-to-errors"},{"type":"paragraph","inlineContent":[{"text":"When the analyzer or its modules’ result streams throw an error, the analysis session becomes finished as described above, and the same error (or a ","type":"text"},{"type":"codeVoice","code":"CancellationError"},{"text":") is thrown from all waiting methods and result streams.","type":"text"}]}]}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["/documentation/speech/speechanalyzer"]}],"hierarchy":{"paths":[["doc://com.apple.documentation/documentation/technologies","doc://com.apple.speech/documentation/Speech"]]},"metadata":{"navigatorTitle":[{"kind":"identifier","text":"SpeechAnalyzer"}],"symbolKind":"class","platforms":[{"unavailable":false,"name":"iOS","deprecated":false,"beta":false,"introducedAt":"26.0"},{"introducedAt":"26.0","name":"iPadOS","deprecated":false,"unavailable":false,"beta":false},{"beta":false,"deprecated":false,"unavailable":false,"name":"Mac Catalyst","introducedAt":"26.0"},{"introducedAt":"26.0","name":"macOS","deprecated":false,"unavailable":false,"beta":false},{"introducedAt":"26.0","name":"visionOS","deprecated":false,"unavailable":false,"beta":false}],"title":"SpeechAnalyzer","externalID":"s:6Speech0A8AnalyzerC","fragments":[{"text":"actor","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"SpeechAnalyzer"}],"roleHeading":"Class","role":"symbol","modules":[{"name":"Speech"}]},"abstract":[{"type":"text","text":"Analyzes spoken audio content in various ways and manages the analysis session."}],"topicSections":[{"title":"Creating an analyzer","anchor":"Creating-an-analyzer","identifiers":["doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/init(modules:options:)","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/init(inputSequence:modules:options:analysisContext:volatileRangeChangedHandler:)","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/init(inputAudioFile:modules:options:analysisContext:finishAfterFile:volatileRangeChangedHandler:)","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/Options"]},{"identifiers":["doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/setModules(_:)","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/modules"],"anchor":"Managing-modules","title":"Managing modules"},{"title":"Performing analysis","anchor":"Performing-analysis","identifiers":["doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/analyzeSequence(_:)","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/analyzeSequence(from:)"]},{"title":"Performing autonomous analysis","identifiers":["doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/start(inputSequence:)","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/start(inputAudioFile:finishAfterFile:)"],"anchor":"Performing-autonomous-analysis"},{"identifiers":["doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/cancelAnalysis(before:)","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finalize(through:)"],"anchor":"Finalizing-and-cancelling-results","title":"Finalizing and cancelling results"},{"identifiers":["doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/cancelAndFinishNow()","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finalizeAndFinishThroughEndOfInput()","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finalizeAndFinish(through:)","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finish(after:)"],"anchor":"Finishing-analysis","title":"Finishing analysis"},{"anchor":"Determining-audio-formats","identifiers":["doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/bestAvailableAudioFormat(compatibleWith:)","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/bestAvailableAudioFormat(compatibleWith:considering:)"],"title":"Determining audio formats"},{"identifiers":["doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/prepareToAnalyze(in:)","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/prepareToAnalyze(in:withProgressReadyHandler:)"],"anchor":"Improving-responsiveness","title":"Improving responsiveness"},{"title":"Monitoring analysis","anchor":"Monitoring-analysis","identifiers":["doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/setVolatileRangeChangedHandler(_:)","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/volatileRange"]},{"title":"Managing contexts","anchor":"Managing-contexts","identifiers":["doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/setContext(_:)","doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/context"]}],"relationshipsSections":[{"kind":"relationships","type":"conformsTo","identifiers":["doc://com.externally.resolved.symbol/s:ScA","doc://com.externally.resolved.symbol/s:s8SendableP","doc://com.externally.resolved.symbol/s:s16SendableMetatypeP"],"title":"Conforms To"}],"sections":[],"kind":"symbol","seeAlsoSections":[{"identifiers":["doc://com.apple.speech/documentation/Speech/bringing-advanced-speech-to-text-capabilities-to-your-app","doc://com.apple.speech/documentation/Speech/AssetInventory"],"generated":true,"anchor":"Essentials","title":"Essentials"}],"references":{"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finalizeAndFinishThroughEndOfInput()":{"abstract":[{"type":"text","text":"Finishes analysis after an audio input sequence has been fully consumed and its results are finalized."}],"type":"topic","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finalizeAndFinishThroughEndOfInput()","kind":"symbol","title":"finalizeAndFinishThroughEndOfInput()","role":"symbol","url":"/documentation/speech/speechanalyzer/finalizeandfinishthroughendofinput()","fragments":[{"kind":"keyword","text":"func"},{"text":" ","kind":"text"},{"kind":"identifier","text":"finalizeAndFinishThroughEndOfInput"},{"text":"() ","kind":"text"},{"text":"async","kind":"keyword"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"}]},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finish(after:)":{"role":"symbol","type":"topic","kind":"symbol","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"finish"},{"text":"(","kind":"text"},{"text":"after","kind":"externalParam"},{"kind":"text","text":": "},{"text":"CMTime","kind":"typeIdentifier","preciseIdentifier":"c:@SA@CMTime"},{"kind":"text","text":") "},{"text":"async","kind":"keyword"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"}],"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finish(after:)","url":"/documentation/speech/speechanalyzer/finish(after:)","title":"finish(after:)","abstract":[{"text":"Finishes analysis once input for a given time is consumed.","type":"text"}]},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/setModules(_:)":{"kind":"symbol","fragments":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"identifier","text":"setModules"},{"text":"([any ","kind":"text"},{"text":"SpeechModule","preciseIdentifier":"s:6Speech0A6ModuleP","kind":"typeIdentifier"},{"text":"]) ","kind":"text"},{"text":"async","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"keyword","text":"throws"}],"abstract":[{"type":"text","text":"Adds or removes modules."}],"title":"setModules(_:)","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/setModules(_:)","type":"topic","role":"symbol","url":"/documentation/speech/speechanalyzer/setmodules(_:)"},"doc://com.apple.speech/documentation/Speech/AssetInventory":{"title":"AssetInventory","abstract":[{"text":"Manages the assets that are necessary for transcription or other analyses.","type":"text"}],"fragments":[{"kind":"keyword","text":"class"},{"text":" ","kind":"text"},{"text":"AssetInventory","kind":"identifier"}],"kind":"symbol","identifier":"doc://com.apple.speech/documentation/Speech/AssetInventory","url":"/documentation/speech/assetinventory","type":"topic","navigatorTitle":[{"kind":"identifier","text":"AssetInventory"}],"role":"symbol"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/setVolatileRangeChangedHandler(_:)":{"type":"topic","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"setVolatileRangeChangedHandler"},{"kind":"text","text":"("},{"kind":"keyword","text":"sending"},{"kind":"text","text":" (("},{"kind":"typeIdentifier","preciseIdentifier":"c:@SA@CMTimeRange","text":"CMTimeRange"},{"text":", ","kind":"text"},{"kind":"typeIdentifier","text":"Bool","preciseIdentifier":"s:Sb"},{"text":", ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:Sb","text":"Bool"},{"text":") -> ","kind":"text"},{"text":"Void","kind":"typeIdentifier","preciseIdentifier":"s:s4Voida"},{"text":")?)","kind":"text"}],"role":"symbol","kind":"symbol","url":"/documentation/speech/speechanalyzer/setvolatilerangechangedhandler(_:)","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/setVolatileRangeChangedHandler(_:)","title":"setVolatileRangeChangedHandler(_:)","abstract":[{"text":"A closure that the analyzer calls when the volatile range changes.","type":"text"}]},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/cancelAnalysis(before:)":{"url":"/documentation/speech/speechanalyzer/cancelanalysis(before:)","kind":"symbol","type":"topic","abstract":[{"type":"text","text":"Stops analyzing audio predating the given time."}],"role":"symbol","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/cancelAnalysis(before:)","title":"cancelAnalysis(before:)","fragments":[{"kind":"keyword","text":"func"},{"text":" ","kind":"text"},{"kind":"identifier","text":"cancelAnalysis"},{"text":"(","kind":"text"},{"text":"before","kind":"externalParam"},{"kind":"text","text":": "},{"text":"CMTime","preciseIdentifier":"c:@SA@CMTime","kind":"typeIdentifier"},{"kind":"text","text":")"}]},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/init(inputAudioFile:modules:options:analysisContext:finishAfterFile:volatileRangeChangedHandler:)":{"type":"topic","fragments":[{"kind":"keyword","text":"convenience"},{"text":" ","kind":"text"},{"text":"init","kind":"identifier"},{"text":"(","kind":"text"},{"text":"inputAudioFile","kind":"externalParam"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"c:objc(cs)AVAudioFile","text":"AVAudioFile"},{"kind":"text","text":", "},{"text":"modules","kind":"externalParam"},{"text":": [any ","kind":"text"},{"text":"SpeechModule","kind":"typeIdentifier","preciseIdentifier":"s:6Speech0A6ModuleP"},{"kind":"text","text":"], "},{"text":"options","kind":"externalParam"},{"kind":"text","text":": "},{"preciseIdentifier":"s:6Speech0A8AnalyzerC","kind":"typeIdentifier","text":"SpeechAnalyzer"},{"text":".","kind":"text"},{"text":"Options","preciseIdentifier":"s:6Speech0A8AnalyzerC7OptionsV","kind":"typeIdentifier"},{"kind":"text","text":"?, "},{"text":"analysisContext","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"AnalysisContext","preciseIdentifier":"s:6Speech15AnalysisContextC","kind":"typeIdentifier"},{"kind":"text","text":", "},{"text":"finishAfterFile","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"Bool","preciseIdentifier":"s:Sb","kind":"typeIdentifier"},{"text":", ","kind":"text"},{"text":"volatileRangeChangedHandler","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"sending","kind":"keyword"},{"text":" ((","kind":"text"},{"preciseIdentifier":"c:@SA@CMTimeRange","text":"CMTimeRange","kind":"typeIdentifier"},{"text":", ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"s:Sb","text":"Bool"},{"text":", ","kind":"text"},{"preciseIdentifier":"s:Sb","text":"Bool","kind":"typeIdentifier"},{"kind":"text","text":") -> "},{"preciseIdentifier":"s:s4Voida","text":"Void","kind":"typeIdentifier"},{"text":")?) ","kind":"text"},{"text":"async","kind":"keyword"},{"text":" ","kind":"text"},{"text":"throws","kind":"keyword"}],"url":"/documentation/speech/speechanalyzer/init(inputaudiofile:modules:options:analysiscontext:finishafterfile:volatilerangechangedhandler:)","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/init(inputAudioFile:modules:options:analysisContext:finishAfterFile:volatileRangeChangedHandler:)","kind":"symbol","abstract":[{"type":"text","text":"Creates an analyzer and begins analysis on an audio file."}],"role":"symbol","title":"init(inputAudioFile:modules:options:analysisContext:finishAfterFile:volatileRangeChangedHandler:)"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/context":{"kind":"symbol","type":"topic","role":"symbol","url":"/documentation/speech/speechanalyzer/context","title":"context","abstract":[{"text":"An object containing contextual information.","type":"text"}],"fragments":[{"text":"var","kind":"keyword"},{"kind":"text","text":" "},{"text":"context","kind":"identifier"},{"kind":"text","text":": "},{"preciseIdentifier":"s:6Speech15AnalysisContextC","text":"AnalysisContext","kind":"typeIdentifier"}],"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/context"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/prepareToAnalyze(in:)":{"kind":"symbol","title":"prepareToAnalyze(in:)","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/prepareToAnalyze(in:)","fragments":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"identifier","text":"prepareToAnalyze"},{"kind":"text","text":"("},{"kind":"externalParam","text":"in"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"c:objc(cs)AVAudioFormat","text":"AVAudioFormat"},{"kind":"text","text":"?) "},{"kind":"keyword","text":"async"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"}],"role":"symbol","url":"/documentation/speech/speechanalyzer/preparetoanalyze(in:)","type":"topic","abstract":[{"type":"text","text":"Prepares the analyzer to begin work with minimal startup delay."}]},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finalize(through:)":{"type":"topic","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finalize(through:)","role":"symbol","title":"finalize(through:)","kind":"symbol","fragments":[{"kind":"keyword","text":"func"},{"text":" ","kind":"text"},{"text":"finalize","kind":"identifier"},{"kind":"text","text":"("},{"text":"through","kind":"externalParam"},{"kind":"text","text":": "},{"text":"CMTime","preciseIdentifier":"c:@SA@CMTime","kind":"typeIdentifier"},{"kind":"text","text":"?) "},{"text":"async","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"keyword","text":"throws"}],"url":"/documentation/speech/speechanalyzer/finalize(through:)","abstract":[{"type":"text","text":"Finalizes the modules’ analyses."}]},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/bestAvailableAudioFormat(compatibleWith:)":{"kind":"symbol","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/bestAvailableAudioFormat(compatibleWith:)","abstract":[{"type":"text","text":"Retrieves the best-quality audio format that the specified modules can work with, from assets installed on the device."}],"title":"bestAvailableAudioFormat(compatibleWith:)","url":"/documentation/speech/speechanalyzer/bestavailableaudioformat(compatiblewith:)","role":"symbol","fragments":[{"text":"static","kind":"keyword"},{"kind":"text","text":" "},{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"bestAvailableAudioFormat"},{"text":"(","kind":"text"},{"kind":"externalParam","text":"compatibleWith"},{"kind":"text","text":": [any "},{"text":"SpeechModule","preciseIdentifier":"s:6Speech0A6ModuleP","kind":"typeIdentifier"},{"text":"]) ","kind":"text"},{"text":"async","kind":"keyword"},{"text":" -> ","kind":"text"},{"preciseIdentifier":"c:objc(cs)AVAudioFormat","kind":"typeIdentifier","text":"AVAudioFormat"},{"kind":"text","text":"?"}],"type":"topic"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finalizeAndFinish(through:)":{"title":"finalizeAndFinish(through:)","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/finalizeAndFinish(through:)","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"finalizeAndFinish"},{"text":"(","kind":"text"},{"text":"through","kind":"externalParam"},{"kind":"text","text":": "},{"text":"CMTime","kind":"typeIdentifier","preciseIdentifier":"c:@SA@CMTime"},{"text":") ","kind":"text"},{"text":"async","kind":"keyword"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"}],"url":"/documentation/speech/speechanalyzer/finalizeandfinish(through:)","role":"symbol","type":"topic","abstract":[{"type":"text","text":"Finishes analysis after finalizing results for a given time-code."}],"kind":"symbol"},"doc://com.apple.speech/documentation/Speech":{"role":"collection","url":"/documentation/speech","kind":"symbol","title":"Speech","identifier":"doc://com.apple.speech/documentation/Speech","abstract":[{"type":"text","text":"Perform speech recognition on live or prerecorded audio, and receive transcriptions, alternative interpretations, and confidence levels of the results."}],"type":"topic"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/init(modules:options:)":{"url":"/documentation/speech/speechanalyzer/init(modules:options:)","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/init(modules:options:)","title":"init(modules:options:)","type":"topic","abstract":[{"text":"Creates an analyzer.","type":"text"}],"kind":"symbol","fragments":[{"kind":"keyword","text":"convenience"},{"kind":"text","text":" "},{"kind":"identifier","text":"init"},{"kind":"text","text":"("},{"kind":"externalParam","text":"modules"},{"kind":"text","text":": [any "},{"kind":"typeIdentifier","preciseIdentifier":"s:6Speech0A6ModuleP","text":"SpeechModule"},{"kind":"text","text":"], "},{"text":"options","kind":"externalParam"},{"kind":"text","text":": "},{"text":"SpeechAnalyzer","kind":"typeIdentifier","preciseIdentifier":"s:6Speech0A8AnalyzerC"},{"text":".","kind":"text"},{"text":"Options","preciseIdentifier":"s:6Speech0A8AnalyzerC7OptionsV","kind":"typeIdentifier"},{"text":"?)","kind":"text"}],"role":"symbol"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/init(inputSequence:modules:options:analysisContext:volatileRangeChangedHandler:)":{"abstract":[{"text":"Creates an analyzer and begins analysis.","type":"text"}],"type":"topic","title":"init(inputSequence:modules:options:analysisContext:volatileRangeChangedHandler:)","fragments":[{"text":"convenience","kind":"keyword"},{"text":" ","kind":"text"},{"text":"init","kind":"identifier"},{"text":"<","kind":"text"},{"kind":"genericParameter","text":"InputSequence"},{"kind":"text","text":">("},{"text":"inputSequence","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"InputSequence","kind":"typeIdentifier"},{"kind":"text","text":", "},{"text":"modules","kind":"externalParam"},{"text":": [any ","kind":"text"},{"text":"SpeechModule","kind":"typeIdentifier","preciseIdentifier":"s:6Speech0A6ModuleP"},{"kind":"text","text":"], "},{"kind":"externalParam","text":"options"},{"text":": ","kind":"text"},{"text":"SpeechAnalyzer","preciseIdentifier":"s:6Speech0A8AnalyzerC","kind":"typeIdentifier"},{"kind":"text","text":"."},{"text":"Options","preciseIdentifier":"s:6Speech0A8AnalyzerC7OptionsV","kind":"typeIdentifier"},{"kind":"text","text":"?, "},{"text":"analysisContext","kind":"externalParam"},{"kind":"text","text":": "},{"text":"AnalysisContext","preciseIdentifier":"s:6Speech15AnalysisContextC","kind":"typeIdentifier"},{"kind":"text","text":", "},{"kind":"externalParam","text":"volatileRangeChangedHandler"},{"kind":"text","text":": "},{"kind":"keyword","text":"sending"},{"kind":"text","text":" (("},{"preciseIdentifier":"c:@SA@CMTimeRange","kind":"typeIdentifier","text":"CMTimeRange"},{"text":", ","kind":"text"},{"preciseIdentifier":"s:Sb","text":"Bool","kind":"typeIdentifier"},{"text":", ","kind":"text"},{"text":"Bool","kind":"typeIdentifier","preciseIdentifier":"s:Sb"},{"kind":"text","text":") -> "},{"text":"Void","kind":"typeIdentifier","preciseIdentifier":"s:s4Voida"},{"text":")?)","kind":"text"}],"url":"/documentation/speech/speechanalyzer/init(inputsequence:modules:options:analysiscontext:volatilerangechangedhandler:)","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/init(inputSequence:modules:options:analysisContext:volatileRangeChangedHandler:)","kind":"symbol","role":"symbol"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/cancelAndFinishNow()":{"abstract":[{"type":"text","text":"Finishes analysis immediately."}],"role":"symbol","kind":"symbol","title":"cancelAndFinishNow()","fragments":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"cancelAndFinishNow","kind":"identifier"},{"text":"() ","kind":"text"},{"text":"async","kind":"keyword"}],"url":"/documentation/speech/speechanalyzer/cancelandfinishnow()","type":"topic","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/cancelAndFinishNow()"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/Options":{"kind":"symbol","url":"/documentation/speech/speechanalyzer/options","navigatorTitle":[{"kind":"identifier","text":"Options"}],"abstract":[{"type":"text","text":"Analysis processing options."}],"role":"symbol","fragments":[{"kind":"keyword","text":"struct"},{"text":" ","kind":"text"},{"text":"Options","kind":"identifier"}],"title":"SpeechAnalyzer.Options","type":"topic","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/Options"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/Options/ModelRetention-swift.enum":{"type":"topic","role":"symbol","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"ModelRetention","kind":"identifier"}],"navigatorTitle":[{"kind":"identifier","text":"ModelRetention"}],"kind":"symbol","abstract":[{"type":"text","text":"A model caching strategy."}],"title":"SpeechAnalyzer.Options.ModelRetention","url":"/documentation/speech/speechanalyzer/options/modelretention-swift.enum","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/Options/ModelRetention-swift.enum"},"doc://com.externally.resolved.symbol/s:s16SendableMetatypeP":{"identifier":"doc://com.externally.resolved.symbol/s:s16SendableMetatypeP","title":"SendableMetatype","role":"symbol","url":"/documentation/Swift/SendableMetatype","abstract":[{"text":"A type whose metatype can be shared across arbitrary concurrent contexts without introducing a risk of data races. When a generic type `T` conforms to `SendableMetatype`, its metatype `T.Type` conforms to `Sendable`.  All concrete types implicitly conform to the `SendableMetatype` protocol, so its primary purpose is in generic code to prohibit the use of isolated conformances along with the generic type.","type":"text"}],"kind":"symbol","type":"topic","fragments":[{"kind":"keyword","text":"protocol"},{"kind":"text","text":" "},{"text":"SendableMetatype","kind":"identifier"},{"text":" : ~Copyable, ~Escapable","kind":"text"}]},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/analyzeSequence(_:)":{"fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"text":"analyzeSequence","kind":"identifier"},{"text":"<","kind":"text"},{"text":"InputSequence","kind":"genericParameter"},{"kind":"text","text":">("},{"kind":"typeIdentifier","text":"InputSequence"},{"kind":"text","text":") "},{"kind":"keyword","text":"async"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"},{"text":" -> ","kind":"text"},{"kind":"typeIdentifier","preciseIdentifier":"c:@SA@CMTime","text":"CMTime"},{"kind":"text","text":"?"}],"url":"/documentation/speech/speechanalyzer/analyzesequence(_:)","abstract":[{"type":"text","text":"Analyzes an input sequence, returning when the sequence is consumed."}],"title":"analyzeSequence(_:)","type":"topic","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/analyzeSequence(_:)","role":"symbol","kind":"symbol"},"doc://com.apple.speech/documentation/Speech/SpeechModule/availableCompatibleAudioFormats":{"url":"/documentation/speech/speechmodule/availablecompatibleaudioformats","type":"topic","title":"availableCompatibleAudioFormats","abstract":[{"type":"text","text":"The audio formats that this module is able to analyze, given its configuration."}],"role":"symbol","kind":"symbol","identifier":"doc://com.apple.speech/documentation/Speech/SpeechModule/availableCompatibleAudioFormats","fragments":[{"text":"var","kind":"keyword"},{"text":" ","kind":"text"},{"text":"availableCompatibleAudioFormats","kind":"identifier"},{"kind":"text","text":": ["},{"text":"AVAudioFormat","preciseIdentifier":"c:objc(cs)AVAudioFormat","kind":"typeIdentifier"},{"text":"]","kind":"text"}],"required":true},"doc://com.apple.documentation/documentation/technologies":{"abstract":[{"text":"","type":"text"}],"role":"overview","url":"/documentation/technologies","kind":"technologies","type":"topic","identifier":"doc://com.apple.documentation/documentation/technologies","title":"Technologies"},"doc://com.apple.speech/documentation/Speech/AnalyzerInput":{"title":"AnalyzerInput","type":"topic","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"AnalyzerInput","kind":"identifier"}],"kind":"symbol","identifier":"doc://com.apple.speech/documentation/Speech/AnalyzerInput","url":"/documentation/speech/analyzerinput","abstract":[{"text":"Time-coded audio data.","type":"text"}],"role":"symbol","navigatorTitle":[{"text":"AnalyzerInput","kind":"identifier"}]},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/volatileRange":{"url":"/documentation/speech/speechanalyzer/volatilerange","fragments":[{"kind":"keyword","text":"var"},{"text":" ","kind":"text"},{"text":"volatileRange","kind":"identifier"},{"text":": ","kind":"text"},{"text":"CMTimeRange","preciseIdentifier":"c:@SA@CMTimeRange","kind":"typeIdentifier"},{"kind":"text","text":"?"}],"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/volatileRange","kind":"symbol","title":"volatileRange","abstract":[{"text":"The range of results that can change.","type":"text"}],"role":"symbol","type":"topic"},"doc://com.externally.resolved.symbol/s:s8SendableP":{"identifier":"doc://com.externally.resolved.symbol/s:s8SendableP","url":"/documentation/Swift/Sendable","fragments":[{"text":"protocol","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"Sendable"},{"kind":"text","text":" : "},{"kind":"typeIdentifier","text":"SendableMetatype","preciseIdentifier":"s:s16SendableMetatypeP"}],"abstract":[{"text":"A thread-safe type whose values can be shared across arbitrary concurrent contexts without introducing a risk of data races.","type":"text"}],"kind":"symbol","role":"symbol","type":"topic","title":"Sendable"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/start(inputAudioFile:finishAfterFile:)":{"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/start(inputAudioFile:finishAfterFile:)","kind":"symbol","role":"symbol","url":"/documentation/speech/speechanalyzer/start(inputaudiofile:finishafterfile:)","title":"start(inputAudioFile:finishAfterFile:)","type":"topic","abstract":[{"type":"text","text":"Starts analysis of an input sequence created from an audio file and returns immediately."}],"fragments":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"start","kind":"identifier"},{"kind":"text","text":"("},{"kind":"externalParam","text":"inputAudioFile"},{"text":": ","kind":"text"},{"text":"AVAudioFile","preciseIdentifier":"c:objc(cs)AVAudioFile","kind":"typeIdentifier"},{"text":", ","kind":"text"},{"kind":"externalParam","text":"finishAfterFile"},{"kind":"text","text":": "},{"preciseIdentifier":"s:Sb","kind":"typeIdentifier","text":"Bool"},{"text":") ","kind":"text"},{"kind":"keyword","text":"async"},{"text":" ","kind":"text"},{"text":"throws","kind":"keyword"}]},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/analyzeSequence(from:)":{"title":"analyzeSequence(from:)","url":"/documentation/speech/speechanalyzer/analyzesequence(from:)","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/analyzeSequence(from:)","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"analyzeSequence"},{"kind":"text","text":"("},{"kind":"externalParam","text":"from"},{"kind":"text","text":": "},{"text":"AVAudioFile","preciseIdentifier":"c:objc(cs)AVAudioFile","kind":"typeIdentifier"},{"text":") ","kind":"text"},{"kind":"keyword","text":"async"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"},{"kind":"text","text":" -> "},{"text":"CMTime","preciseIdentifier":"c:@SA@CMTime","kind":"typeIdentifier"},{"kind":"text","text":"?"}],"kind":"symbol","role":"symbol","abstract":[{"type":"text","text":"Analyzes an input sequence created from an audio file, returning when the file has been read."}],"type":"topic"},"doc://com.externally.resolved.symbol/s:ScA":{"url":"/documentation/Swift/Actor","role":"symbol","kind":"symbol","identifier":"doc://com.externally.resolved.symbol/s:ScA","abstract":[{"type":"text","text":"Common protocol to which all actors conform."}],"title":"Actor","type":"topic","fragments":[{"text":"protocol","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"Actor"},{"text":" : AnyObject, ","kind":"text"},{"preciseIdentifier":"s:s8SendableP","kind":"typeIdentifier","text":"Sendable"}]},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/setContext(_:)":{"role":"symbol","title":"setContext(_:)","fragments":[{"text":"func","kind":"keyword"},{"kind":"text","text":" "},{"text":"setContext","kind":"identifier"},{"kind":"text","text":"("},{"preciseIdentifier":"s:6Speech15AnalysisContextC","text":"AnalysisContext","kind":"typeIdentifier"},{"text":") ","kind":"text"},{"kind":"keyword","text":"async"},{"kind":"text","text":" "},{"text":"throws","kind":"keyword"}],"kind":"symbol","type":"topic","url":"/documentation/speech/speechanalyzer/setcontext(_:)","abstract":[{"text":"Sets contextual information to improve or inform the analysis.","type":"text"}],"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/setContext(_:)"},"doc://com.apple.speech/documentation/Speech/SpeechTranscriber":{"navigatorTitle":[{"kind":"identifier","text":"SpeechTranscriber"}],"url":"/documentation/speech/speechtranscriber","type":"topic","abstract":[{"type":"text","text":"A speech-to-text transcription module that’s appropriate for normal conversation and general purposes."}],"title":"SpeechTranscriber","kind":"symbol","role":"symbol","fragments":[{"text":"class","kind":"keyword"},{"text":" ","kind":"text"},{"text":"SpeechTranscriber","kind":"identifier"}],"identifier":"doc://com.apple.speech/documentation/Speech/SpeechTranscriber"},"doc://com.apple.speech/documentation/Speech/bringing-advanced-speech-to-text-capabilities-to-your-app":{"kind":"article","abstract":[{"text":"Learn how to incorporate live speech-to-text transcription into your app with SpeechAnalyzer.","type":"text"}],"type":"topic","title":"Bringing advanced speech-to-text capabilities to your app","role":"sampleCode","url":"/documentation/speech/bringing-advanced-speech-to-text-capabilities-to-your-app","identifier":"doc://com.apple.speech/documentation/Speech/bringing-advanced-speech-to-text-capabilities-to-your-app"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer":{"abstract":[{"type":"text","text":"Analyzes spoken audio content in various ways and manages the analysis session."}],"kind":"symbol","fragments":[{"text":"actor","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"SpeechAnalyzer"}],"type":"topic","navigatorTitle":[{"text":"SpeechAnalyzer","kind":"identifier"}],"url":"/documentation/speech/speechanalyzer","title":"SpeechAnalyzer","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer","role":"symbol"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/modules":{"fragments":[{"text":"var","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"identifier","text":"modules"},{"text":": [any ","kind":"text"},{"preciseIdentifier":"s:6Speech0A6ModuleP","kind":"typeIdentifier","text":"SpeechModule"},{"text":"]","kind":"text"}],"title":"modules","kind":"symbol","abstract":[{"type":"text","text":"The modules performing analysis on the audio input."}],"url":"/documentation/speech/speechanalyzer/modules","type":"topic","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/modules","role":"symbol"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/bestAvailableAudioFormat(compatibleWith:considering:)":{"role":"symbol","abstract":[{"text":"Retrieves the best-quality audio format that the specified modules can work with, taking into account the natural format of the audio and assets installed on the device.","type":"text"}],"fragments":[{"text":"static","kind":"keyword"},{"text":" ","kind":"text"},{"text":"func","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"bestAvailableAudioFormat"},{"text":"(","kind":"text"},{"kind":"externalParam","text":"compatibleWith"},{"kind":"text","text":": [any "},{"kind":"typeIdentifier","text":"SpeechModule","preciseIdentifier":"s:6Speech0A6ModuleP"},{"kind":"text","text":"], "},{"kind":"externalParam","text":"considering"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","text":"AVAudioFormat","preciseIdentifier":"c:objc(cs)AVAudioFormat"},{"kind":"text","text":"?) "},{"text":"async","kind":"keyword"},{"kind":"text","text":" -> "},{"preciseIdentifier":"c:objc(cs)AVAudioFormat","text":"AVAudioFormat","kind":"typeIdentifier"},{"kind":"text","text":"?"}],"title":"bestAvailableAudioFormat(compatibleWith:considering:)","type":"topic","url":"/documentation/speech/speechanalyzer/bestavailableaudioformat(compatiblewith:considering:)","kind":"symbol","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/bestAvailableAudioFormat(compatibleWith:considering:)"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/start(inputSequence:)":{"role":"symbol","fragments":[{"kind":"keyword","text":"func"},{"text":" ","kind":"text"},{"text":"start","kind":"identifier"},{"text":"<","kind":"text"},{"kind":"genericParameter","text":"InputSequence"},{"kind":"text","text":">("},{"kind":"externalParam","text":"inputSequence"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"InputSequence"},{"kind":"text","text":") "},{"kind":"keyword","text":"async"},{"text":" ","kind":"text"},{"text":"throws","kind":"keyword"}],"title":"start(inputSequence:)","url":"/documentation/speech/speechanalyzer/start(inputsequence:)","abstract":[{"type":"text","text":"Starts analysis of an input sequence and returns immediately."}],"identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/start(inputSequence:)","kind":"symbol","type":"topic"},"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/prepareToAnalyze(in:withProgressReadyHandler:)":{"type":"topic","role":"symbol","abstract":[{"type":"text","text":"Prepares the analyzer to begin work with minimal startup delay, reporting the progress of that preparation."}],"url":"/documentation/speech/speechanalyzer/preparetoanalyze(in:withprogressreadyhandler:)","identifier":"doc://com.apple.speech/documentation/Speech/SpeechAnalyzer/prepareToAnalyze(in:withProgressReadyHandler:)","kind":"symbol","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"text":"prepareToAnalyze","kind":"identifier"},{"text":"(","kind":"text"},{"kind":"externalParam","text":"in"},{"text":": ","kind":"text"},{"kind":"typeIdentifier","text":"AVAudioFormat","preciseIdentifier":"c:objc(cs)AVAudioFormat"},{"text":"?, ","kind":"text"},{"kind":"externalParam","text":"withProgressReadyHandler"},{"kind":"text","text":": "},{"kind":"keyword","text":"sending"},{"kind":"text","text":" (("},{"kind":"typeIdentifier","text":"Progress","preciseIdentifier":"c:objc(cs)NSProgress"},{"text":") -> ","kind":"text"},{"preciseIdentifier":"s:s4Voida","text":"Void","kind":"typeIdentifier"},{"text":")?) ","kind":"text"},{"text":"async","kind":"keyword"},{"kind":"text","text":" "},{"text":"throws","kind":"keyword"}],"title":"prepareToAnalyze(in:withProgressReadyHandler:)"}},"legalNotices":{"copyright":"Copyright &copy; 2026 Apple Inc. All rights reserved.","termsOfUse":"https://www.apple.com/legal/internet-services/terms/site.html","privacyPolicy":"https://www.apple.com/privacy/privacy-policy"}}